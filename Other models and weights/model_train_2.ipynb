{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Input, Dropout, Flatten\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.utils import plot_model\n",
    "from keras.applications.vgg16 import VGG16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 263s 4us/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 48, 48, 3)]       0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 48, 48, 64)        1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 48, 48, 64)        36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 24, 24, 64)        0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 24, 24, 128)       73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 24, 24, 128)       147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 12, 12, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 12, 12, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 12, 12, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 6, 6, 256)         0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 6, 6, 512)         1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 6, 6, 512)         2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 3, 3, 512)         0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 3, 3, 512)         2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
      "                                                                 \n",
      " sequential (Sequential)     (None, 7)                 133127    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,847,815\n",
      "Trainable params: 133,127\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "Found 28821 images belonging to 7 classes.\n",
      "Found 7066 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "img_size = 48\n",
    "batch_size = 64\n",
    "\n",
    "base_path = \"C:\\\\Users\\\\arvin\\\\OneDrive\\\\Desktop\\\\miniproj\\\\\"\n",
    "\n",
    "# Load pre-trained model without classifier\n",
    "vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Freeze layers of pre-trained model\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create new classifier for transfer learning\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=vgg_model.output_shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "# Combine pre-trained model with new classifier\n",
    "model = Model(inputs=vgg_model.input, outputs=model(vgg_model.output))\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Data generator to augment data for training\n",
    "datagen_train = ImageDataGenerator(horizontal_flip=True)\n",
    "train_generator = datagen_train.flow_from_directory(base_path+\"train\", \n",
    "                                                    target_size=(img_size,img_size), \n",
    "                                                    color_mode='rgb',\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=True)\n",
    "\n",
    "# Data generator to augment data for validation\n",
    "datagen_validation = ImageDataGenerator(horizontal_flip=True)\n",
    "validation_generator = datagen_train.flow_from_directory(base_path+\"validation\", \n",
    "                                                    target_size=(img_size,img_size), \n",
    "                                                    color_mode='rgb',\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   class_mode='categorical',\n",
    "                                                   shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 6.1678 - accuracy: 0.2497\n",
      "Epoch 1: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 336s 743ms/step - loss: 6.1678 - accuracy: 0.2497 - val_loss: 1.8500 - val_accuracy: 0.3078 - lr: 5.0000e-04\n",
      "Epoch 2/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.8812 - accuracy: 0.2954\n",
      "Epoch 2: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 422s 938ms/step - loss: 1.8812 - accuracy: 0.2954 - val_loss: 1.6997 - val_accuracy: 0.3331 - lr: 5.0000e-04\n",
      "Epoch 3/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.7291 - accuracy: 0.3189\n",
      "Epoch 3: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 203s 451ms/step - loss: 1.7291 - accuracy: 0.3189 - val_loss: 1.6535 - val_accuracy: 0.3594 - lr: 5.0000e-04\n",
      "Epoch 4/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.6785 - accuracy: 0.3341\n",
      "Epoch 4: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 239s 531ms/step - loss: 1.6785 - accuracy: 0.3341 - val_loss: 1.6295 - val_accuracy: 0.3624 - lr: 5.0000e-04\n",
      "Epoch 5/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.6454 - accuracy: 0.3428\n",
      "Epoch 5: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 241s 535ms/step - loss: 1.6454 - accuracy: 0.3428 - val_loss: 1.5967 - val_accuracy: 0.3820 - lr: 5.0000e-04\n",
      "Epoch 6/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.6219 - accuracy: 0.3601\n",
      "Epoch 6: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 251s 557ms/step - loss: 1.6219 - accuracy: 0.3601 - val_loss: 1.5962 - val_accuracy: 0.3893 - lr: 5.0000e-04\n",
      "Epoch 7/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.6050 - accuracy: 0.3643\n",
      "Epoch 7: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 252s 560ms/step - loss: 1.6050 - accuracy: 0.3643 - val_loss: 1.5879 - val_accuracy: 0.3955 - lr: 5.0000e-04\n",
      "Epoch 8/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.5753 - accuracy: 0.3770\n",
      "Epoch 8: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 242s 538ms/step - loss: 1.5753 - accuracy: 0.3770 - val_loss: 1.5731 - val_accuracy: 0.4030 - lr: 5.0000e-04\n",
      "Epoch 9/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.5648 - accuracy: 0.3830\n",
      "Epoch 9: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 226s 502ms/step - loss: 1.5648 - accuracy: 0.3830 - val_loss: 1.5808 - val_accuracy: 0.3960 - lr: 5.0000e-04\n",
      "Epoch 10/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.5550 - accuracy: 0.3815\n",
      "Epoch 10: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 241s 537ms/step - loss: 1.5550 - accuracy: 0.3815 - val_loss: 1.5686 - val_accuracy: 0.3952 - lr: 5.0000e-04\n",
      "Epoch 11/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.5400 - accuracy: 0.3934\n",
      "Epoch 11: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 224s 498ms/step - loss: 1.5400 - accuracy: 0.3934 - val_loss: 1.5591 - val_accuracy: 0.4003 - lr: 5.0000e-04\n",
      "Epoch 12/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.5225 - accuracy: 0.4009\n",
      "Epoch 12: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 224s 498ms/step - loss: 1.5225 - accuracy: 0.4009 - val_loss: 1.5537 - val_accuracy: 0.4115 - lr: 5.0000e-04\n",
      "Epoch 13/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.5151 - accuracy: 0.4057\n",
      "Epoch 13: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 240s 533ms/step - loss: 1.5151 - accuracy: 0.4057 - val_loss: 1.5542 - val_accuracy: 0.4151 - lr: 5.0000e-04\n",
      "Epoch 14/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.5025 - accuracy: 0.4133\n",
      "Epoch 14: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 226s 502ms/step - loss: 1.5025 - accuracy: 0.4133 - val_loss: 1.5465 - val_accuracy: 0.4125 - lr: 5.0000e-04\n",
      "Epoch 15/15\n",
      "450/450 [==============================] - ETA: 0s - loss: 1.4924 - accuracy: 0.4129\n",
      "Epoch 15: saving model to new_model_weights.h5\n",
      "450/450 [==============================] - 239s 530ms/step - loss: 1.4924 - accuracy: 0.4129 - val_loss: 1.5463 - val_accuracy: 0.4114 - lr: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "steps_per_epoch= train_generator.n//train_generator.batch_size\n",
    "validation_steps = validation_generator.n//validation_generator.batch_size\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"new_model_weights.h5\",monitor='val_accuracy',\n",
    "                            save_weights_only=True, mode='max',verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss' , factor=0.1, patience=2, min_lr=0.00001,model='auto')\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit(\n",
    "        x= train_generator,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        epochs=epochs,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=validation_steps,\n",
    "        callbacks=callbacks\n",
    ")\n",
    "\n",
    "model_json = model.to_json()\n",
    "with open(\"new_model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59b8bae32ae535ad7f778145d834fc75c2d3e41fc284115aa6b25c7fb41e16b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
